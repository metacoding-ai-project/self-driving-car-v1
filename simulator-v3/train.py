# train.py
import pygame
import numpy as np
import matplotlib.pyplot as plt
import random
from environment import GridEnvironment
from car import Car
from agent import DQNAgent
from config import CURRENT_SPEED, NUM_EPISODES, SHOW_TRAINING, NUM_MAPS, MAPS_PER_EPISODE, RANDOM_SEED

# ìž¬í˜„ ê°€ëŠ¥í•œ ì‹¤í—˜ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

def train():
    # ì´ˆê¸°í™”
    pygame.init()
    env = GridEnvironment(random_map=True)  # ì²« ë§µì€ ëžœë¤
    agent = DQNAgent()

    # í†µê³„
    episode_rewards = []
    episode_lengths = []
    recent_rewards = []
    goal_reached_count = 0  # ëª©ì ì§€ ë„ë‹¬ íšŸìˆ˜
    map_success_count = {}  # ë§µë³„ ì„±ê³µ íšŸìˆ˜

    num_episodes = NUM_EPISODES

    # í°íŠ¸ ì„¤ì •
    font = pygame.font.Font(None, 30)
    small_font = pygame.font.Font(None, 24)

    print("=" * 60)
    print("ðŸš— ìžìœ¨ì£¼í–‰ ê°•í™”í•™ìŠµ ì‹œë®¬ë ˆì´í„° v2 - ì¼ë°˜í™” ê²½ë¡œ ì°¾ê¸°")
    print("=" * 60)
    print(f"ì´ ì—í”¼ì†Œë“œ: {num_episodes}")
    print(f"ë§µ ê°œìˆ˜: {NUM_MAPS}ê°œ")
    print(f"ë§µë‹¹ ì—í”¼ì†Œë“œ: ì•½ {MAPS_PER_EPISODE}ê°œ")
    print("í›ˆë ¨ì„ ì‹œìž‘í•©ë‹ˆë‹¤!")
    print("ì—¬ëŸ¬ ë§µì—ì„œ í•™ìŠµí•˜ì—¬ ì¼ë°˜í™”ëœ ê²½ë¡œ ì°¾ê¸°ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.")
    print("ESCë¥¼ ëˆ„ë¥´ë©´ ì¤‘ê°„ì— ì¢…ë£Œí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")
    print("=" * 60)

    running = True
    current_map_id = None

    for episode in range(num_episodes):
        if not running:
            break

        # ë§¤ ì—í”¼ì†Œë“œë§ˆë‹¤ ë‹¤ë¥¸ ë§µ ì‚¬ìš© (ì¼ì • ì£¼ê¸°ë§ˆë‹¤)
        if episode % MAPS_PER_EPISODE == 0:
            current_map_id = random.randint(0, NUM_MAPS - 1)
            env.reset_map(current_map_id)
            if current_map_id not in map_success_count:
                map_success_count[current_map_id] = 0

        # ëžœë¤ ì‹œìž‘ì /ëª©ì ì§€ (ë§¤ ì—í”¼ì†Œë“œë§ˆë‹¤)
        start_x, start_y = env.start_pos
        car = Car(start_x, start_y)
        state = env.get_state(car.x, car.y, car.direction)

        episode_reward = 0
        episode_length = 0
        done = False
        reached_goal = False

        while not done and running:
            # ì´ë²¤íŠ¸ ì²˜ë¦¬
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    running = False
                    break
                if event.type == pygame.KEYDOWN:
                    if event.key == pygame.K_ESCAPE:
                        running = False
                        break

            # í–‰ë™ ì„ íƒ
            action = agent.select_action(state, training=True)

            # í–‰ë™ ì‹¤í–‰
            reward, done = car.move(action, env)
            next_state = env.get_state(car.x, car.y, car.direction)

            # ëª©ì ì§€ ë„ë‹¬ ì²´í¬
            if env.is_goal(car.x, car.y):
                reached_goal = True
                if current_map_id is not None:
                    map_success_count[current_map_id] += 1

            # ë©”ëª¨ë¦¬ì— ì €ìž¥
            agent.memory.push(state, action, reward, next_state, done)

            # í•™ìŠµ
            loss = agent.train_step()

            # í™”ë©´ í‘œì‹œ (SHOW_TRAININGì´ Trueì¼ ë•Œë§Œ)
            if SHOW_TRAINING:
                env.draw(car)

                # í•™ìŠµ ì •ë³´ í‘œì‹œ
                avg_reward = np.mean(recent_rewards[-20:]) if len(recent_rewards) > 0 else 0

                # ìƒë‹¨ ì •ë³´ íŒ¨ë„ (ë°˜íˆ¬ëª… ë°°ê²½)
                info_surface = pygame.Surface((env.screen.get_width(), 140))
                info_surface.set_alpha(200)
                info_surface.fill((0, 0, 0))
                env.screen.blit(info_surface, (0, 0))

                # í…ìŠ¤íŠ¸ ì •ë³´
                y_offset = 10
                texts = [
                    f"Episode: {episode + 1}/{num_episodes}  |  Goal Reached: {goal_reached_count}",
                    f"Map ID: {current_map_id}  |  Map Success: {map_success_count.get(current_map_id, 0)}",
                    f"Score: {car.score:.1f}  |  Steps: {car.steps}",
                    f"Epsilon: {agent.epsilon:.3f}  |  Avg Reward: {avg_reward:.1f}",
                    f"Speed: {CURRENT_SPEED} FPS",
                ]

                for text in texts:
                    text_surface = small_font.render(text, True, (255, 255, 255))
                    env.screen.blit(text_surface, (10, y_offset))
                    y_offset += 26

                # ëª©ì ì§€ ë„ë‹¬ ì‹œ ì¶•í•˜ ë©”ì‹œì§€
                if reached_goal:
                    congrats_text = font.render("ðŸŽ‰ GOAL!", True, (255, 255, 0))
                    text_rect = congrats_text.get_rect(
                        center=(env.screen.get_width() // 2, env.screen.get_height() // 2)
                    )
                    env.screen.blit(congrats_text, text_rect)

                # ì§„í–‰ë¥  ë°”
                progress = (episode + 1) / num_episodes
                bar_width = env.screen.get_width() - 20
                bar_height = 20
                bar_x = 10
                bar_y = 115

                # ë°°ê²½ (íšŒìƒ‰)
                pygame.draw.rect(env.screen, (50, 50, 50),
                               (bar_x, bar_y, bar_width, bar_height))
                # ì§„í–‰ë¥  (ë…¹ìƒ‰)
                pygame.draw.rect(env.screen, (0, 255, 0),
                               (bar_x, bar_y, int(bar_width * progress), bar_height))
                # í…Œë‘ë¦¬
                pygame.draw.rect(env.screen, (255, 255, 255),
                               (bar_x, bar_y, bar_width, bar_height), 2)

                pygame.display.flip()

                # ì†ë„ ì¡°ì ˆ (FPS) - config.pyì—ì„œ ì„¤ì •!
                env.clock.tick(CURRENT_SPEED)

            state = next_state
            episode_reward += reward
            episode_length += 1

        # í†µê³„ ê¸°ë¡
        episode_rewards.append(episode_reward)
        episode_lengths.append(episode_length)
        recent_rewards.append(episode_reward)

        # ëª©ì ì§€ ë„ë‹¬ ì¹´ìš´íŠ¸
        if reached_goal:
            goal_reached_count += 1

        # ì½˜ì†” ë¡œê·¸ ì¶œë ¥
        if episode % 10 == 0:
            avg_reward = np.mean(episode_rewards[-10:]) if len(episode_rewards) >= 10 else episode_reward
            avg_length = np.mean(episode_lengths[-10:]) if len(episode_lengths) >= 10 else episode_length
            goal_str = "ðŸŽ¯" if reached_goal else "  "
            success_rate = (goal_reached_count / (episode + 1)) * 100
            print(f"Episode {episode:4d} {goal_str} | "
                  f"Reward: {episode_reward:7.1f} | "
                  f"Avg: {avg_reward:7.1f} | "
                  f"Steps: {episode_length:4d} | "
                  f"Goals: {goal_reached_count:4d} ({success_rate:5.1f}%) | "
                  f"Epsilon: {agent.epsilon:.3f} | "
                  f"LR: {agent.learning_rate:.6f} | "
                  f"Map: {current_map_id}")

        # ëª¨ë¸ ì €ìž¥ (200 ì—í”¼ì†Œë“œë§ˆë‹¤)
        if episode % 200 == 0 and episode > 0:
            agent.save(f"model_episode_{episode}.pth")
            print(f"âœ… ëª¨ë¸ ì €ìž¥: model_episode_{episode}.pth")

    # ìµœì¢… ëª¨ë¸ ì €ìž¥
    if running:
        agent.save("model_final.pth")
        print("=" * 60)
        print("âœ… í›ˆë ¨ ì™„ë£Œ! ìµœì¢… ëª¨ë¸ ì €ìž¥ë¨: model_final.pth")
        print(f"ì´ ëª©ì ì§€ ë„ë‹¬: {goal_reached_count}/{num_episodes} ({goal_reached_count/num_episodes*100:.1f}%)")
        print("=" * 60)

        # ê²°ê³¼ ê·¸ëž˜í”„
        plot_results(episode_rewards, episode_lengths, map_success_count)
    else:
        print("=" * 60)
        print("âš ï¸  í›ˆë ¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("=" * 60)

    pygame.quit()

def plot_results(rewards, lengths, map_success_count):
    """ê²°ê³¼ ì‹œê°í™”"""
    fig = plt.figure(figsize=(15, 10))
    
    # ë³´ìƒ ê·¸ëž˜í”„
    ax1 = plt.subplot(2, 2, 1)
    ax1.plot(rewards, alpha=0.3, label='Episode Reward', color='blue')
    if len(rewards) >= 10:
        moving_avg = np.convolve(rewards, np.ones(10)/10, mode='valid')
        ax1.plot(range(9, len(rewards)), moving_avg, label='Moving Average (10)',
                color='red', linewidth=2)
    ax1.set_xlabel('Episode')
    ax1.set_ylabel('Reward')
    ax1.set_title('Training Rewards')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # ê¸¸ì´ ê·¸ëž˜í”„
    ax2 = plt.subplot(2, 2, 2)
    ax2.plot(lengths, alpha=0.3, label='Episode Length', color='green')
    if len(lengths) >= 10:
        moving_avg = np.convolve(lengths, np.ones(10)/10, mode='valid')
        ax2.plot(range(9, len(lengths)), moving_avg, label='Moving Average (10)',
                color='red', linewidth=2)
    ax2.set_xlabel('Episode')
    ax2.set_ylabel('Steps')
    ax2.set_title('Episode Lengths')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # ë§µë³„ ì„±ê³µë¥ 
    ax3 = plt.subplot(2, 2, 3)
    if map_success_count:
        map_ids = sorted(map_success_count.keys())
        success_counts = [map_success_count[mid] for mid in map_ids]
        ax3.bar(map_ids, success_counts, color='green', alpha=0.7)
        ax3.set_xlabel('Map ID')
        ax3.set_ylabel('Success Count')
        ax3.set_title('Success Count per Map')
        ax3.grid(True, alpha=0.3, axis='y')

    # ì„±ê³µë¥  ì¶”ì´
    ax4 = plt.subplot(2, 2, 4)
    success_rates = []
    goal_count = 0
    for i in range(len(rewards)):
        if rewards[i] >= 50:  # ëª©ì ì§€ ë„ë‹¬ë¡œ ê°„ì£¼ (reward >= 50)
            goal_count += 1
        success_rates.append(goal_count / (i + 1) * 100)
    
    ax4.plot(success_rates, color='purple', linewidth=2)
    ax4.set_xlabel('Episode')
    ax4.set_ylabel('Success Rate (%)')
    ax4.set_title('Success Rate Over Time')
    ax4.grid(True, alpha=0.3)
    ax4.set_ylim([0, 100])

    plt.tight_layout()
    plt.savefig('training_results.png', dpi=150)
    print("ðŸ“Š ê·¸ëž˜í”„ ì €ìž¥: training_results.png")
    plt.show()

if __name__ == "__main__":
    train()
